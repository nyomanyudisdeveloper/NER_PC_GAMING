{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import InputLayer, TimeDistributed, SpatialDropout1D, Bidirectional\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json \n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DatasetTag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat</th>\n",
       "      <th>kata</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kalimat 1</td>\n",
       "      <td>forza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-Game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kalimat 1</td>\n",
       "      <td>horizon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E-Game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kalimat 1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kalimat 1</td>\n",
       "      <td>om</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalimat 1</td>\n",
       "      <td>install</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>Kalimat 449</td>\n",
       "      <td>putih</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>Kalimat 450</td>\n",
       "      <td>ganti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>Kalimat 450</td>\n",
       "      <td>mobonya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-Spek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>Kalimat 450</td>\n",
       "      <td>b660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>Kalimat 450</td>\n",
       "      <td>gan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2363 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Kalimat     kata  pos        tag\n",
       "0       Kalimat 1    forza  NaN     B-Game\n",
       "1       Kalimat 1  horizon  NaN     E-Game\n",
       "2       Kalimat 1        5  NaN          O\n",
       "3       Kalimat 1       om  NaN          O\n",
       "4       Kalimat 1  install  NaN          O\n",
       "...           ...      ...  ...        ...\n",
       "2358  Kalimat 449    putih  NaN          O\n",
       "2359  Kalimat 450    ganti  NaN  B-Request\n",
       "2360  Kalimat 450  mobonya  NaN     B-Spek\n",
       "2361  Kalimat 450     b660  NaN          O\n",
       "2362  Kalimat 450      gan  NaN          O\n",
       "\n",
       "[2363 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Kalimat','kata','tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kalimat    0\n",
       "kata       0\n",
       "tag        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/8g19f6x13sn907v0ff4vkmm80000gn/T/ipykernel_3566/1379821321.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in corpus: 753\n",
      "Unique tags in corpus: 44\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique words in corpus:\", df['kata'].nunique())\n",
    "print(\"Unique tags in corpus:\", df['tag'].nunique())\n",
    "\n",
    "words = list(set(df[\"kata\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "num_words = len(words)\n",
    "\n",
    "tags = list(set(df[\"tag\"].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/8g19f6x13sn907v0ff4vkmm80000gn/T/ipykernel_3566/1759589013.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  self.grouped = self.df.groupby(\"Kalimat\").apply(agg)\n"
     ]
    }
   ],
   "source": [
    "# Class to get sentences\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s: [(w, t) for w, t in zip(s['kata'].values.tolist(),\n",
    "                                                s['tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Kalimat\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Kalimat: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "# Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kak', 'O'),\n",
       " ('jakarta', 'B-Tempat'),\n",
       " ('timur', 'E-Tempat'),\n",
       " ('pakai', 'O'),\n",
       " ('packing', 'B-Pengiriman'),\n",
       " ('kayu', 'E-Pengiriman'),\n",
       " ('aman', 'O')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[514, 496, 733],\n",
       " [232, 360, 388, 658, 607, 502, 173],\n",
       " [733, 476, 40, 354, 731, 19, 20, 182, 233, 395, 224],\n",
       " [1, 230, 586, 377, 294],\n",
       " [331, 480, 62, 733],\n",
       " [271, 489],\n",
       " [691, 378, 733],\n",
       " [70, 460, 487, 733, 460, 707, 45, 130, 431],\n",
       " [667, 271, 489, 442, 705],\n",
       " [40, 443, 182, 36],\n",
       " [389, 159, 344],\n",
       " [168, 588],\n",
       " [223, 733, 398, 586],\n",
       " [309, 667, 594],\n",
       " [723, 223, 529, 690, 223, 729, 675, 599],\n",
       " [398, 75, 309, 733],\n",
       " [169, 657, 188, 733],\n",
       " [454, 473, 200, 311, 317, 173, 482, 248],\n",
       " [41, 644, 199],\n",
       " [707, 658, 454],\n",
       " [667, 227],\n",
       " [24, 67, 282],\n",
       " [232, 131, 732],\n",
       " [520, 657, 733],\n",
       " [724, 464, 733],\n",
       " [639, 520, 472, 70, 183, 566, 137, 391],\n",
       " [480, 40],\n",
       " [667, 271, 489, 733],\n",
       " [733, 398, 586, 3, 309, 313],\n",
       " [21, 733],\n",
       " [733, 396, 359, 658, 522, 91, 707, 657],\n",
       " [309, 667, 271, 489, 733],\n",
       " [733, 460, 738, 114, 707, 640, 254, 76],\n",
       " [686, 132],\n",
       " [362],\n",
       " [392, 305, 703, 292, 195, 510],\n",
       " [733,\n",
       "  169,\n",
       "  188,\n",
       "  629,\n",
       "  334,\n",
       "  460,\n",
       "  431,\n",
       "  646,\n",
       "  629,\n",
       "  733,\n",
       "  571,\n",
       "  7,\n",
       "  657,\n",
       "  629,\n",
       "  733,\n",
       "  516,\n",
       "  260],\n",
       " [733, 320, 123, 191],\n",
       " [570, 499, 512, 182, 463, 672, 733],\n",
       " [144, 331, 454],\n",
       " [642, 183, 454],\n",
       " [743, 733],\n",
       " [707, 460, 431, 43],\n",
       " [454, 632, 103, 44],\n",
       " [244, 256, 733],\n",
       " [78, 174, 220, 454, 667, 40, 520, 384, 724],\n",
       " [181, 238, 734, 89, 473, 475, 61, 643, 175, 319, 280],\n",
       " [314, 460, 174, 385, 733],\n",
       " [14,\n",
       "  232,\n",
       "  481,\n",
       "  232,\n",
       "  32,\n",
       "  539,\n",
       "  715,\n",
       "  374,\n",
       "  715,\n",
       "  653,\n",
       "  291,\n",
       "  441,\n",
       "  750,\n",
       "  186,\n",
       "  346,\n",
       "  212,\n",
       "  251],\n",
       " [271, 489, 227, 672],\n",
       " [305, 21, 753, 40, 733],\n",
       " [602, 141, 689, 672, 733],\n",
       " [465, 33, 505, 283],\n",
       " [40, 494, 486],\n",
       " [40, 470],\n",
       " [612, 125, 52, 383, 127, 418, 592, 355],\n",
       " [707, 460, 415, 646, 232],\n",
       " [179, 662, 70, 140, 454],\n",
       " [70, 379, 13, 733],\n",
       " [202, 542, 126, 236, 309],\n",
       " [70, 183],\n",
       " [21, 451, 657, 707, 431, 167, 285, 646, 618, 174],\n",
       " [517, 506, 404],\n",
       " [21, 451],\n",
       " [667, 663, 309, 733],\n",
       " [470, 223],\n",
       " [183, 432, 169],\n",
       " [473, 531, 623, 502, 733, 490],\n",
       " [520, 242, 5, 667, 40, 278, 424, 550],\n",
       " [40, 543, 294],\n",
       " [70, 649, 2, 32, 126, 721, 188],\n",
       " [662, 70, 188, 113, 387],\n",
       " [314, 651, 275, 567, 518, 12, 687],\n",
       " [631, 529, 371, 307, 88, 667, 745, 232, 711, 336, 345],\n",
       " [667, 464, 213],\n",
       " [684, 735],\n",
       " [192, 210, 733],\n",
       " [42, 740, 321, 691, 223],\n",
       " [294, 65, 436, 211],\n",
       " [259, 40, 301, 624, 40, 636, 15, 699, 664, 449, 40, 172],\n",
       " [398, 3, 223],\n",
       " [733, 25, 188, 188, 432, 629],\n",
       " [600, 472, 705, 159, 92, 322],\n",
       " [667, 635, 672, 213],\n",
       " [593, 635, 672, 629, 213],\n",
       " [40, 568, 537, 17, 619, 513, 733],\n",
       " [646, 314, 261, 636, 40, 733],\n",
       " [667, 40, 677, 59, 633, 342, 223],\n",
       " [658, 603, 64, 462, 331, 611],\n",
       " [32, 520, 657, 707, 341, 330, 646, 516, 260],\n",
       " [473, 50, 135, 658, 607, 502],\n",
       " [684, 432, 171],\n",
       " [717, 733, 520, 516, 260],\n",
       " [213, 331, 218, 559],\n",
       " [213, 393, 197, 61, 86],\n",
       " [733, 684, 460, 440, 314, 201, 646, 733],\n",
       " [667, 40, 464],\n",
       " [232, 539, 658, 715, 305, 473, 541, 245, 428],\n",
       " [696, 100, 733, 40, 59],\n",
       " [733, 40, 266, 357, 433, 583, 8],\n",
       " [667, 398, 586, 223, 733, 735, 687],\n",
       " [667, 480, 40, 477, 335],\n",
       " [40, 1, 230],\n",
       " [733, 309, 82, 120, 84, 209, 147, 680, 348],\n",
       " [667, 221],\n",
       " [82, 581, 40, 288, 631, 677, 348, 575, 389, 350, 309, 354],\n",
       " [309, 120, 277, 4, 159, 232],\n",
       " [696, 309, 667, 477, 655, 232],\n",
       " [213, 667, 691, 573, 223, 313],\n",
       " [21, 520, 314, 618],\n",
       " [229, 213],\n",
       " [733, 667, 166, 113, 529, 257, 309],\n",
       " [613,\n",
       "  280,\n",
       "  733,\n",
       "  667,\n",
       "  40,\n",
       "  726,\n",
       "  298,\n",
       "  272,\n",
       "  672,\n",
       "  40,\n",
       "  106,\n",
       "  544,\n",
       "  672,\n",
       "  427,\n",
       "  629,\n",
       "  612,\n",
       "  213,\n",
       "  104,\n",
       "  22,\n",
       "  520,\n",
       "  555],\n",
       " [733, 520, 659, 485],\n",
       " [331, 460, 736],\n",
       " [667, 1, 230, 586, 309, 733, 686, 313],\n",
       " [667, 40, 689, 600],\n",
       " [581, 511, 309],\n",
       " [93, 552],\n",
       " [672, 667, 42, 740, 213],\n",
       " [561, 367],\n",
       " [227, 271, 223, 187, 31, 356],\n",
       " [684, 686, 687],\n",
       " [213, 442, 705, 40, 641, 152, 174, 79],\n",
       " [733, 520, 450, 58],\n",
       " [733, 460, 45, 718, 646],\n",
       " [458, 471, 672, 629, 223],\n",
       " [153, 21, 733, 735, 687, 696],\n",
       " [696, 309, 667, 691],\n",
       " [63, 450, 727, 629, 454],\n",
       " [667, 729, 733, 223],\n",
       " [40, 497],\n",
       " [696, 735, 687, 309, 667, 222, 390, 113, 56, 213],\n",
       " [255, 737],\n",
       " [667, 398, 3, 309],\n",
       " [618, 460, 315, 213],\n",
       " [733, 612, 514, 533, 240, 753, 40],\n",
       " [45, 718, 646, 733],\n",
       " [365, 364, 40, 59],\n",
       " [213, 667, 332, 386, 645],\n",
       " [213, 686, 753, 425, 40],\n",
       " [213, 270, 658, 751, 637, 598, 514],\n",
       " [733, 520, 309, 40, 556, 590],\n",
       " [705],\n",
       " [667, 227, 470, 223],\n",
       " [86, 667, 594, 230, 595, 223, 213],\n",
       " [735, 687, 696, 166, 113, 672, 232, 223],\n",
       " [733, 169, 460, 467, 586, 199, 646],\n",
       " [520, 309, 312, 448, 489, 354, 223],\n",
       " [232, 169, 460, 70, 188, 432, 188, 498, 646, 320, 497],\n",
       " [480, 40, 398, 8, 539, 454],\n",
       " [421, 182, 512, 553, 223],\n",
       " [244, 60, 733],\n",
       " [667, 1, 586, 223, 733],\n",
       " [733, 323, 708],\n",
       " [327],\n",
       " [262, 213],\n",
       " [667, 101, 284, 204, 223, 454],\n",
       " [331, 733],\n",
       " [667, 398, 586, 174, 196, 437, 232],\n",
       " [733, 450, 171, 707, 696, 540, 709, 460, 718, 733, 515, 295],\n",
       " [70, 188, 454],\n",
       " [454, 667, 407, 564],\n",
       " [213, 601, 187, 82, 363, 213, 724, 542, 296, 481, 213, 22, 582],\n",
       " [32, 588, 331],\n",
       " [481, 450, 331, 105],\n",
       " [733, 725, 705, 227, 328, 534, 138],\n",
       " [473, 523, 658, 194, 173, 733],\n",
       " [473, 576, 753, 40, 372],\n",
       " [520, 54, 368, 250, 450, 584],\n",
       " [667, 398, 106, 309],\n",
       " [520, 450, 171, 331],\n",
       " [365, 364],\n",
       " [477, 213],\n",
       " [314, 480, 414, 687],\n",
       " [684, 461, 309, 667, 398, 232],\n",
       " [271, 402, 338, 469, 629, 733],\n",
       " [227, 223],\n",
       " [351, 667, 631],\n",
       " [524, 208, 243, 382, 373, 672, 733],\n",
       " [680, 228, 682, 672],\n",
       " [442, 705, 40, 309, 451],\n",
       " [656, 728, 695, 672, 733],\n",
       " [156, 733, 520, 472, 684, 735, 687],\n",
       " [33, 618, 315, 286, 658, 519],\n",
       " [667, 412, 554, 313, 380, 232],\n",
       " [552, 584, 232, 66, 220, 486, 220, 520, 667, 136, 313, 711],\n",
       " [658, 312, 40, 59],\n",
       " [733, 193, 520, 472, 161, 179, 520, 472, 658, 145, 733],\n",
       " [58, 520, 450, 171, 450, 171, 536],\n",
       " [483,\n",
       "  612,\n",
       "  733,\n",
       "  174,\n",
       "  305,\n",
       "  702,\n",
       "  113,\n",
       "  652,\n",
       "  533,\n",
       "  400,\n",
       "  348,\n",
       "  533,\n",
       "  190,\n",
       "  274,\n",
       "  164,\n",
       "  358,\n",
       "  634,\n",
       "  473,\n",
       "  360,\n",
       "  430],\n",
       " [40, 269, 596, 313, 711, 672],\n",
       " [454, 667, 602],\n",
       " [40, 287, 454],\n",
       " [279, 279],\n",
       " [160, 416, 539, 454],\n",
       " [305, 213],\n",
       " [232, 40, 706, 584],\n",
       " [667, 166, 113, 672, 313, 711],\n",
       " [667, 398, 106],\n",
       " [94, 50, 232, 727, 707],\n",
       " [733, 610, 354, 724, 730],\n",
       " [450, 735, 19, 739],\n",
       " [289, 320, 191, 733, 142],\n",
       " [681, 667, 321, 678, 714, 213],\n",
       " [205, 720, 733, 235, 657],\n",
       " [213, 737, 111, 40, 478, 303, 349, 557],\n",
       " [608, 178, 673, 749, 520, 426],\n",
       " [590, 525, 77, 309, 629, 733],\n",
       " [320, 34, 617],\n",
       " [225, 454],\n",
       " [454, 442, 705, 580, 337],\n",
       " [733, 667, 398, 3],\n",
       " [678, 489, 227, 633, 549, 150],\n",
       " [309, 658, 350, 232],\n",
       " [40, 232, 444, 309],\n",
       " [232, 32, 520, 450, 171, 331, 64, 704, 249],\n",
       " [213, 667, 40, 677, 313, 529, 257, 10, 225, 309, 213],\n",
       " [232, 612, 606, 539, 658, 545, 241, 232],\n",
       " [21, 320, 191],\n",
       " [232, 612, 667, 677, 529, 257, 590, 672, 102, 159, 539, 524, 747, 449, 123],\n",
       " [667, 271, 489, 380, 338],\n",
       " [667, 227, 223, 377],\n",
       " [474, 188],\n",
       " [193, 74, 226, 265, 354, 38, 290, 185, 679, 341, 707, 348],\n",
       " [381, 456, 57, 380, 309, 733],\n",
       " [40, 365, 364, 675],\n",
       " [581, 40, 59, 309, 733],\n",
       " [667, 631, 309, 454],\n",
       " [452, 32, 305, 638, 253],\n",
       " [753, 40, 631],\n",
       " [381, 494, 486, 672],\n",
       " [477, 213],\n",
       " [324, 314, 654, 618, 404],\n",
       " [451, 40, 753, 686, 40],\n",
       " [667, 551, 590, 672],\n",
       " [667, 470, 691, 573, 590, 309, 733],\n",
       " [590, 40, 442, 705, 40, 520],\n",
       " [58, 520, 171, 239, 171, 450, 681, 191, 733, 109],\n",
       " [188, 213],\n",
       " [658, 331, 19, 47, 232],\n",
       " [690, 309, 232],\n",
       " [442, 705, 40],\n",
       " [227, 513, 402, 398, 586, 513, 402],\n",
       " [124, 514, 149],\n",
       " [667, 729, 227],\n",
       " [442, 581, 309, 232],\n",
       " [466, 159, 4, 51, 382, 373, 213],\n",
       " [707],\n",
       " [733, 691, 643, 598, 160],\n",
       " [667, 470, 223],\n",
       " [305, 48, 320, 329, 263, 615, 305, 535, 32, 585, 35, 59, 625, 32, 320],\n",
       " [213, 667, 398, 3],\n",
       " [213, 667, 227, 513, 529, 257, 223, 213],\n",
       " [667, 271, 489, 675, 402, 223, 733, 469, 629],\n",
       " [667, 712, 408, 318, 223, 339],\n",
       " [460, 314, 117, 687, 684, 293, 733],\n",
       " [271, 489, 223, 213],\n",
       " [70, 188, 174],\n",
       " [552, 629, 213, 684, 432, 735],\n",
       " [331, 19, 646, 733],\n",
       " [520, 472, 331, 633, 588, 432, 687, 21],\n",
       " [333, 364, 733],\n",
       " [232, 633, 588, 232, 300, 174, 331, 113, 474, 419, 219, 660, 302],\n",
       " [748, 716, 733, 54, 491],\n",
       " [666, 121, 733],\n",
       " [213, 90],\n",
       " [539, 473],\n",
       " [733, 520, 616, 733],\n",
       " [213, 472, 166, 113],\n",
       " [213, 124, 520, 331],\n",
       " [213, 601, 520, 331],\n",
       " [376, 32, 110, 502, 213],\n",
       " [232, 667, 40, 458, 694, 484, 139, 154, 357, 354, 516, 260],\n",
       " [21, 232, 473],\n",
       " [509, 31, 213, 321, 223],\n",
       " [77, 309],\n",
       " [232, 413, 528, 184, 74, 232],\n",
       " [733, 477],\n",
       " [547, 27, 324, 460, 404],\n",
       " [398, 106, 309],\n",
       " [232, 520, 54, 232],\n",
       " [213, 159, 4, 389, 277, 672],\n",
       " [267, 521, 455, 325],\n",
       " [213, 707, 559, 667, 227],\n",
       " [170, 86, 223, 232, 667, 227, 398],\n",
       " [232, 323, 538, 604],\n",
       " [232, 741, 237, 26, 526, 179, 559, 107, 120, 277],\n",
       " [707, 323, 331],\n",
       " [45, 462, 61, 58],\n",
       " [636, 40],\n",
       " [247, 479, 324],\n",
       " [314, 684, 618, 81, 647, 552, 646, 58],\n",
       " [700, 237, 432, 214, 457, 549, 733],\n",
       " [40, 276, 622, 55, 653, 462, 735, 687, 157, 232],\n",
       " [232, 700, 237, 461, 173, 40, 304, 304, 77, 511, 410],\n",
       " [232, 667, 321, 402, 527, 223],\n",
       " [294, 40, 634],\n",
       " [37],\n",
       " [232, 667, 729, 227, 653, 97],\n",
       " [331, 61],\n",
       " [648, 271, 489, 520, 605],\n",
       " [72, 106, 166, 113, 323, 280, 226, 560, 560],\n",
       " [150, 53, 59, 159, 665, 76, 520, 669, 150],\n",
       " [454, 116, 40, 658, 495],\n",
       " [667, 548, 596, 2],\n",
       " [232, 18, 472, 400, 68, 128],\n",
       " [514, 453, 353],\n",
       " [600, 32, 657, 314, 343, 618, 404, 33, 600, 473, 658, 516, 260, 600],\n",
       " [473, 409, 322, 607, 658, 502, 232],\n",
       " [33, 113, 331, 232],\n",
       " [309, 312, 458, 231, 446, 405, 280, 213],\n",
       " [70, 188, 354],\n",
       " [46, 624, 439, 281, 473, 693, 206],\n",
       " [213, 658, 607, 502, 569, 607, 502, 520, 591, 174, 627],\n",
       " [40, 69, 59, 232],\n",
       " [232, 170, 237, 171, 667, 271, 402, 422, 223, 232],\n",
       " [232, 705, 667, 227, 691, 309, 232],\n",
       " [58, 520, 450, 28, 520, 450, 19],\n",
       " [316, 417, 658, 692, 459, 629],\n",
       " [700, 237, 432, 450, 21, 733],\n",
       " [473, 447, 388, 658, 607, 502, 629],\n",
       " [232, 312, 40, 398, 586, 3, 232],\n",
       " [481, 543, 48, 520],\n",
       " [707, 559, 58],\n",
       " [667, 631, 148, 96, 159, 309, 733],\n",
       " [351, 733, 504, 552, 633, 588],\n",
       " [392, 170, 237, 735, 21, 733],\n",
       " [213, 473, 628, 646, 607, 502, 629, 607, 502, 252],\n",
       " [667, 398],\n",
       " [232, 741, 237, 707, 559, 667, 448],\n",
       " [216, 598, 40],\n",
       " [733, 551, 398, 586],\n",
       " [454, 612, 667, 40, 271, 489, 309, 454, 246, 454],\n",
       " [312, 609, 113, 309, 629, 232],\n",
       " [331, 629],\n",
       " [232, 667, 40, 90],\n",
       " [733, 403, 392, 237, 461, 488, 460, 707, 86],\n",
       " [351, 198, 331, 354],\n",
       " [213, 752, 584, 300, 520, 9, 115, 300, 393],\n",
       " [473, 626, 162, 102, 565, 661, 399, 260],\n",
       " [232, 520, 176, 73],\n",
       " [579, 180, 529, 257, 213, 473, 39],\n",
       " [667, 271, 489, 402, 338, 309],\n",
       " [232, 462, 707, 431, 742, 12, 171, 76, 309, 232, 667, 398, 3],\n",
       " [473, 503, 447, 646, 607, 502],\n",
       " [633, 588, 331, 323, 308, 232],\n",
       " [520, 280, 309, 312, 40, 354, 733],\n",
       " [530, 64, 603, 48, 563, 601, 520, 377],\n",
       " [232, 294, 267, 365, 398, 348],\n",
       " [213, 98, 406, 658, 34, 99],\n",
       " [522, 429, 698, 105],\n",
       " [423, 725, 129, 589, 74, 11],\n",
       " [271, 232],\n",
       " [320, 552, 733],\n",
       " [667, 464, 108, 584, 658, 522, 429, 461],\n",
       " [23, 687, 204],\n",
       " [232, 462, 587, 468, 133, 262, 392, 300, 61],\n",
       " [232, 667, 40, 227, 223, 469],\n",
       " [314, 630, 261, 457, 460, 366, 733],\n",
       " [733, 314, 630, 343, 646],\n",
       " [160, 706, 83, 706],\n",
       " [672, 674, 496, 733],\n",
       " [707, 733],\n",
       " [462, 522, 676, 291, 687, 119, 460, 347, 574, 254],\n",
       " [232, 420, 70, 183, 252],\n",
       " [744, 620, 658, 676, 285],\n",
       " [707, 460, 522, 676, 285, 733],\n",
       " [153, 331, 64, 603, 733],\n",
       " [707, 460, 91, 733, 105, 707],\n",
       " [320, 701, 368],\n",
       " [481, 733, 688, 666, 668],\n",
       " [213, 143, 469, 724, 363, 95, 464],\n",
       " [158, 234, 605],\n",
       " [71, 707, 522, 676, 658, 105, 600, 746, 352, 629],\n",
       " [733, 163, 44, 629],\n",
       " [232, 598, 40, 494, 486, 232],\n",
       " [413, 528, 464, 733],\n",
       " [697, 707],\n",
       " [314, 460, 404],\n",
       " [684, 657, 629, 733],\n",
       " [213, 460, 268, 438],\n",
       " [733,\n",
       "  155,\n",
       "  460,\n",
       "  174,\n",
       "  618,\n",
       "  460,\n",
       "  112,\n",
       "  314,\n",
       "  113,\n",
       "  707,\n",
       "  522,\n",
       "  429,\n",
       "  461,\n",
       "  614,\n",
       "  500,\n",
       "  134,\n",
       "  254],\n",
       " [460, 314, 343, 646],\n",
       " [662],\n",
       " [460, 662, 70, 492, 646, 733],\n",
       " [460, 314, 671, 343, 618, 111, 508, 558, 207],\n",
       " [40, 597, 318],\n",
       " [460, 99, 297, 733],\n",
       " [662, 70, 188],\n",
       " [733, 309, 159, 41, 357, 662, 70, 658, 562, 309],\n",
       " [213, 667, 165, 477, 655],\n",
       " [577, 90, 398, 3, 299, 146],\n",
       " [21, 232, 392, 657, 169],\n",
       " [377, 394, 356, 501, 59, 629],\n",
       " [381, 456, 57, 309, 529, 257],\n",
       " [621],\n",
       " [370, 454],\n",
       " [244, 435],\n",
       " [733, 174, 588, 474, 64, 603, 331, 131],\n",
       " [442, 705],\n",
       " [21, 733],\n",
       " [273, 454],\n",
       " [454, 32, 160, 30, 683, 6, 454],\n",
       " [203, 340, 77],\n",
       " [305, 21],\n",
       " [507, 215, 533, 217, 215, 449],\n",
       " [480, 40],\n",
       " [733, 70, 188],\n",
       " [183, 174, 662, 70, 232],\n",
       " [658, 442, 177, 361, 672, 454],\n",
       " [294, 271],\n",
       " [733, 122, 310, 39, 369, 189, 578],\n",
       " [460, 45, 130, 285, 733],\n",
       " [646, 618, 174, 710],\n",
       " [305],\n",
       " [733, 21, 475, 61, 733],\n",
       " [719, 151],\n",
       " [598, 40, 80, 722, 486, 108],\n",
       " [460, 457, 420, 487, 629, 733, 188, 496],\n",
       " [667, 713, 318, 87, 113],\n",
       " [232, 131, 572, 48, 21],\n",
       " [232, 131, 572, 48, 85],\n",
       " [70, 188],\n",
       " [733, 707, 460, 45, 415, 733],\n",
       " [733, 352, 520, 533],\n",
       " [667, 398, 586, 3, 227, 733],\n",
       " [294, 685, 546, 377],\n",
       " [733, 707, 460, 45, 445, 285, 29, 16],\n",
       " [733, 460, 331, 314, 343, 733],\n",
       " [40, 598],\n",
       " [159, 4, 733, 306, 520, 159, 4, 320],\n",
       " [401, 670, 451],\n",
       " [375],\n",
       " [460, 662, 434, 411, 733, 552],\n",
       " [707, 397, 707, 21],\n",
       " [733, 514, 498, 243, 532],\n",
       " [733],\n",
       " [658, 493, 241, 326, 232, 539],\n",
       " [733, 650, 715, 41, 539, 258, 49],\n",
       " [667, 271, 489, 529, 257, 454],\n",
       " [633, 588, 270, 658],\n",
       " [442, 581, 118, 511],\n",
       " [569],\n",
       " [264, 633, 588],\n",
       " [707, 486, 687],\n",
       " [733, 160, 706],\n",
       " [454, 667, 398, 586, 106]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 70)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58, 520, 450, ..., 753, 753, 753],\n",
       "       [700, 237, 432, ..., 753, 753, 753],\n",
       "       [667, 412, 554, ..., 753, 753, 753],\n",
       "       ...,\n",
       "       [684, 657, 629, ..., 753, 753, 753],\n",
       "       [158, 234, 605, ..., 753, 753, 753],\n",
       "       [232, 323, 538, ..., 753, 753, 753]], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,800</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m37,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │       \u001b[38;5;34m120,800\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,500</span> (619.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m158,500\u001b[0m (619.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,500</span> (619.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m158,500\u001b[0m (619.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the embedding dimension\n",
    "embedding_dim = 50  # This is an example value; choose based on your needs\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(InputLayer((max_len,)))\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.1))\n",
    "model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5376 - loss: 5.8345 - val_accuracy: 0.9512 - val_loss: 1.0734\n",
      "Epoch 2/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9532 - loss: 0.7950 - val_accuracy: 0.9556 - val_loss: 0.4120\n",
      "Epoch 3/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9574 - loss: 0.3339 - val_accuracy: 0.9563 - val_loss: 0.3548\n",
      "Epoch 4/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9602 - loss: 0.2539 - val_accuracy: 0.9579 - val_loss: 0.3264\n",
      "Epoch 5/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9638 - loss: 0.2139 - val_accuracy: 0.9591 - val_loss: 0.3066\n",
      "Epoch 6/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9671 - loss: 0.1883 - val_accuracy: 0.9587 - val_loss: 0.3006\n",
      "Epoch 7/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9671 - loss: 0.1830 - val_accuracy: 0.9595 - val_loss: 0.2963\n",
      "Epoch 8/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9669 - loss: 0.1706 - val_accuracy: 0.9607 - val_loss: 0.2741\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "batch_size = 20\n",
    "epochs = 8\n",
    "\n",
    "history = model.fit(x_train, np.array(y_train), batch_size=batch_size, epochs=epochs,\n",
    "                    validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9721 - loss: 0.1472 - val_accuracy: 0.9675 - val_loss: 0.2703\n",
      "Epoch 2/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9783 - loss: 0.1415 - val_accuracy: 0.9583 - val_loss: 0.3552\n",
      "Epoch 3/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9739 - loss: 0.1913 - val_accuracy: 0.9627 - val_loss: 0.3018\n",
      "Epoch 4/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9743 - loss: 0.2000 - val_accuracy: 0.9611 - val_loss: 0.3034\n",
      "Epoch 5/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9767 - loss: 0.1661 - val_accuracy: 0.9651 - val_loss: 0.3002\n",
      "Epoch 6/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9797 - loss: 0.1442 - val_accuracy: 0.9611 - val_loss: 0.3091\n",
      "Epoch 7/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9737 - loss: 0.1965 - val_accuracy: 0.9607 - val_loss: 0.3183\n",
      "Epoch 8/8\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9783 - loss: 0.1713 - val_accuracy: 0.9643 - val_loss: 0.2987\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, np.array(y_train), batch_size=batch_size, epochs=epochs,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_test_true = np.argmax(y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 35, 27, 35, 27, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
       "       35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
       "       35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
       "       35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
       "       35, 35])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training Results\n",
    "\n",
    "model_lstm_1_hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(data=model_lstm_1_hist_df[['accuracy', 'val_accuracy']])\n",
    "plt.grid()\n",
    "plt.title('Accuracy vs Val-Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(data=model_lstm_1_hist_df[['loss', 'val_loss']])\n",
    "plt.grid()\n",
    "plt.title('Loss vs Val-Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inferential = np.array([[264, 554, 404, 668, 404, 668, 581, 753, 753, 753, 753, 753, 753,\n",
    "       753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753,\n",
    "       753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753,\n",
    "       753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753,\n",
    "       753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753, 753,\n",
    "       753, 753, 753, 753, 753]])\n",
    "predict = model.predict(data_inferential)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model SVM after hyperparamter tuning to file model_svm.pkl\n",
    "with open('model.pkl', 'wb') as file_1:\n",
    "  pickle.dump(model, file_1)\n",
    "\n",
    "with open(\"word_dict.txt\", 'w') as file_2:\n",
    "  json.dump(word2idx,file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
